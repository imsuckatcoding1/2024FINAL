

# 네이버쇼핑 리뷰를 KOELECTRA를 사용하여 긍부정 예측
KOELECTRA를 사용하여 네이버 쇼핑리뷰의 긍부정 예측

## 1. 개요

### 1.1 문제 정의
네이버 쇼핑은 수많은 소비자와 판매자가 교류하는 국내 최대의 온라인 쇼핑 플랫폼으로, 다양한 상품 정보를 비교하고 구매 결정을 내릴 수 있는 공간이다. 특히, 사용자는 상품에 대한 리뷰와 평점을 통해 구매를 고려하는 과정에서 중요한 판단 자료를 얻는다. 이러한 리뷰는 상품의 실제 사용 경험을 기반으로 작성되므로 소비자 신뢰도와 구매 의사 결정에 큰 영향을 미친다.

상품 리뷰는 단순히 개인의 의견을 공유하는 것을 넘어, 소비자와 판매자 모두에게 중요한 역할을 한다. 소비자들은 리뷰를 통해 상품의 품질, 성능, 또는 사용의 편리성을 미리 파악할 수 있고, 판매자는 이를 기반으로 상품을 개선하거나 더 나은 마케팅 전략을 수립할 수 있다. 긍정적인 리뷰는 상품의 신뢰도를 높이고 판매량을 증가시키는 반면, 부정적인 리뷰는 구매를 망설이게 하는 요인이 될 수 있다.

이 프로젝트에서는 네이버 쇼핑에 게시된 리뷰 데이터를 분석하여 소비자들이 상품을 신뢰하고 구매로 이어지는 데 영향을 미치는 주요 요인을 탐구하고자 한다. 더 나아가, 리뷰 내용과 평점을 바탕으로 리뷰의 긍정 또는 부정 여부를 자동으로 예측할 수 있는 인공지능 모델을 개발한다. 이를 통해 소비자들에게는 더 나은 구매 경험을, 판매자들에게는 서비스와 제품의 개선 방향성을 제시할 수 있을 것으로 기대된다.

<div> <img src = "https://github.com/imsuckatcoding1/2024FINAL/issues/1#issue-2747514739" width="800"></div>


### 1.2 데이터 및 모델 개요

데이터는 (https://github.com/bab2min/corpus/tree/master/sentiment)를  활용하여 총 20만 건의 데이터에 대해서 사전 학습 언어 모델의 재학습을 수행한다.


| 입력 | 모델 |출력|
|----------|---|---|
| 네이버쇼핑 문장 | koelectra |부정(0), 긍정(1)|

네이버 쇼핑리뷰 수집 기간은 2020년 5월부터 2020년 06월까지 수집하였고 네이버의 여러 제품에 달린 한국어 리뷰를 수집함.데이터는 탭으로 분리 긍정과 부정의 비율이 1:1에 가깝도록 수집.
KoELECTRA는 한국어 자연어 처리(NLP) 작업에 최적화된 언어 모델로, 구글의 ELECTRA 모델을 기반으로 만들어졌다. ELECTRA는 트랜스포머(Transformer) 아키텍처를 기반으로 하며, 기존의 언어 모델(BERT 등)과 달리 새로운 방식의 사전 학습 메커니즘을 활용하여 더 빠르고 효율적으로 동작하는 것이 특징이다. KoELECTRA는 이 ELECTRA 모델을 한국어 데이터로 학습시킨 버전이다.


## 2. 데이터

## 2.1 탐색적 분석

| | review |label|
|-|----------|---|
|0|배공빠르고 굿|0|
|1|택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고|0|
|2|아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 엉성하긴 하지만 편하고 가성비 최고예요.|1|
|3|선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전화했더니 바로주신다했지만 배송도 누락되어있었네요.. 확인안하고 바로 선물했으면 큰일날뻔했네요..이렇게 배송이 오래걸렸으면 사는거 다시 생각했을거같아요 아쉽네요..|1|
|..|...|...|...|
|99997|민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ|0|
|99998|비추합니다 계란 뒤집을 때 완전 불편해요 ㅠㅠ 코팅도 묻어나고 보기엔 예쁘고 실용적으로 보였는데 생각보다 진짜 별로입니다.|1|
|99999|넉넉한 길이로 주문했는데도 안 맞네요 별로예요|1|

200000개의 리뷰가 있고 부정은 0, 긍정은 1로 구성.

|-|건수|
|-|----|
|긍정|99,963|
|부정|100,037|
|계|200,000|

긍정과 부정의 비율이 1:1이 되도록 구성하였고, 부정적인 데이터가 조금 많다. 

## 2.2 데이터 전처리

데이터의 결측치는 확인해본 결과, 없는 것으로 나타났다.

![결측치](https://github.com/yeon0306/steam_game/assets/112537146/e306de7c-3cb0-4de4-aada-41a0547b1b67)

- 리뷰 문장 25자 이상 길이의 분포도

![25자 이상분포표](https://github.com/yeon0306/steam_game/assets/112537146/f7dfccbc-a867-47cc-b399-bd489f8f71d3)

약 30자 이상 ~ 40자 이하의 리뷰 데이터가 가장 많은 것을 알 수 있다. 
리뷰 데이터가 25자 이하의 짧은 리뷰는 매우 제한적이며 정보가 부족하다고 판단하여 25자 이하의 데이터 36317건을 삭제하였다.


- 최종 데이터셋

| | review |label|
|-|----------|---|
|0|배공빠르고 굿|0|
|1|막노동 체험판 막노동 하는사람인데 장비를 내가 사야돼 뭐지|0|
|2|차악!차악!!차악!!! 정말 이래서 왕국을 되찾을 수 있는거야??|1|
|3|시간 때우기에 좋음.. 도전과제는 50시간이면 다 깰 수 있어요|1|
|..|...|...|...|
|63680|엔딩도 이해가고 림보라는 제목을 정말 잘 지었어 근데 왜 도대체 이런 게임을 인디 ...|0|
|63681|야생을 사랑하는 사람들을 위한 짧지만 여운이 남는 이야기. 영어는 그리 어렵지 않습니다.|1|
|63682|한국의 메탈레이지를 떠오르게한다 진짜 손맛으로 하는게임|1|

100,000 건이었던 데이터에서 전처리를 마친 후 최종 데이터셋은 63,683건이 되었다.


- 긍정(1)/부정(0) 파이차트 

<div><img src="https://github.com/yeon0306/steam_game/assets/112537146/a59e1266-cb99-4fa8-90d7-682a5d568faf" width="500"></div>

데이터 전처리 후에도 긍/부정 데이터가 1:1 비율로 나누어져있으며 부정적인 데이터가 32037건, 긍정적인 데이터가 31646건으로 부정적인 데이터가 조금 더 많은 것을 알 수 있다.

- 학습과 검증 데이터셋 분리

![데이터구조](https://github.com/yeon0306/steam_game/assets/112537146/2fdefda9-b41d-4a51-bfaa-dd0dbe26600a)

긍정적인 리뷰 데이터 2000개와 부정적인 리뷰 데이터 2000개를 랜덤으로 추출하여 총 4000개로 만들어졌다.

![학습데이터수](https://github.com/yeon0306/steam_game/assets/112537146/d063f8b6-1a2f-4b5b-ba76-f1874abd9fa0)

학습 데이터 3200개, 검증 데이터 800개로 분리하였다. 
  
- 랜덤으로 추출한 학습 데이터의 구성

| | review |label|
|-|----------|---|
|0|방치형 게임인데 최상의 생산구조를 구축하면됩니다 잊고살다가 몇달뒤에 다시 들어오시면 됩니다|1|
|1|(+) 아름다운 배경 지루하지 않은 시스템 (-) 스토리 많이 빈약함|1|
|2|적당한 플레이타임 나름 괜찮다. 세일할때 사자|1|
|..|...|...|...|
|3999|이 게임 개꿀잼이였는데 제작진 내부갈등으로 공중분해되고 출시 일주일만에 망함|0|
|4000|프레임 드랍이 너무 심해서 도저히 게임을 진행할 수가 없습니다. 그리고 역시나 우려했던 서버 렉도...|0|
|4001|언제나 최고의 돈독오른 게임. 섬란 카구라가 세일해서 2만원인대인데 그넘의...|0|

랜덤으로 추출한 학습 데이터의 결과는 optimizer를 여러번 수정하여 돌려보았지만 정확도가 **0.4 에서 0.7** 로 매우 낮은 정확도로 나타났다. 
학습 데이터의 정확도가 낮은 이유를 찾아본 결과 **리뷰 데이터의 오류** 일 가능성이 높다고 판단하였다.  

- 데이터의 오류 예시 

| | review |label|
|-|----------|---|
|0|주의하실 점. 블랙 플래그에서 DLC로 프리덤 크라이를 사셧다면, 굳이 이 게임을 구매하실 필요는 없습니다.|1|
|1|HOMM시리즈와 차이가 있긴 한데 그게 유의미하게 느껴지진 않았다.|1|
|2|한글 자막이나 관련된 자료 같은게 있을까요...?|1|
|..|...|...|...|
|3999|처음 평점 남깁니다. 아름답고 슬프고 소름돋는 최고의 게임. 어떤 미사여구가 더 필요할까요?|0|
|4000|7000시간밖에 안해서 잘 모르겠지만 정말 갓겜이네요^^|0|
|4001|한국어가 나왔으면 좋겠다. 이거 나름 한국 팬도 있는데 말이다.ㅠㅠ|0|

랜덤으로 추출한 학습 데이터의 애매한 리뷰 데이터들이다. 긍정인 리뷰는 부정으로 보이기도 하며 부정인 리뷰는 긍정으로 보이기도 한다.
또한 게임 리뷰와 관련없는 내용의 데이터들이 매우 많아 모델이 제대로 학습할 수 없는 것을 알 수 있다. 

- 임의로 추출한 학습 데이터의 구성 

| | review |label|
|-|----------|---|
|0|시간 때우기에 좋음.. 도전과제는 50시간이면 다 깰 수 있어요 |1|
|1|역시 재미있네요 전작에서 할수 없었던 자유로운 덱 빌딩도 좋네요^^|1|
|2|포켓볼 1도 몰랐는데, 이걸로 배워 갑니다. 심심할때 하면 좋아요. 컴퓨터 상대하는거 제대로 이겨보고 싶은데 잘 안되네요.|1|
|..|...|...|
|1000|림월드 생각하고 구입할생각이라면 하지마시길... 물론 난 환불~|0|
|1001|사람들의 좋은 평에 이끌려서 샀으나 결과는? 좆노잼 미친노잼|0|
|1001|어떤 미친 러시아인이 지랄해서 죽이는데 관리자네 좆같은게임 왜하냐|0|

리뷰를 읽었을 때 긍정인지 부정인지 판단할 수 없는 리뷰들은 모두 제외하고 사람이 읽었을 때 긍부정인지 판단할 수 있는 정도의 리뷰 데이터만
긍정적인 리뷰 500개, 부정적인 리뷰 500개으로 총 1000개의 데이터셋을 만들었다. 학습 데이터는 800개, 검증 데이터는 200개로 분리하였다. 

<table>
      <tr><th align="center" colspan='6'>데이터셋 1000 </th></tr>
      <tr><th>긍정</th><td>500</td><th>학습</th><td>800</td></tr>
      <tr><th>부정</th><td>500</td><th>검증</th><td>200</td></tr>
</table>

# 3. 재학습 결과

## 3.1 개발 환경
<img src="https://img.shields.io/badge/pycharm-000000?style=flat-square&logo=pycharm&logoColor=white"/> <img src="https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=Python&logoColor=white"/> <img src="https://img.shields.io/badge/torch-EE4C2C?style=flat-square&logo=pytorch&logoColor=white"/> <img src="https://img.shields.io/badge/pandas-150458?style=flat-square&logo=pandas&logoColor=white"/> <img src="https://img.shields.io/badge/numpy-013243?style=flat-square&logo=numpy&logoColor=white"/> <img src="https://img.shields.io/badge/transformers-81c147?style=flat-square&logo=transformers&logoColor=white"/> <img src="https://img.shields.io/badge/scikit-learn-F7931E?style=flat-square&logo=scikit-learn&logoColor=white"/>

## 3.2 KOELECTRA fine-tuning

KOELECTRA 모델을 fine-tuning하는 과정에서 1:1 비율로 구성된 1000개의 학습 데이터를 사용했다. 데이터를 학습시킨 후 전체 데이터인 63,683개에 적용하여 모델을 테스트했다.

## 3.3 학습 결과 그래프


<div><img src="https://github.com/yeon0306/steam_game/assets/112537146/bc55087b-e460-472f-a834-86ee7afdac7f" width="400"><img src="https://github.com/yeon0306/steam_game/assets/112537146/66851e62-ec7d-4f09-b7c8-730789279208" width="400"></div>

<table>
  <tr align="center"><th></th><th></th><th>Epoch 1</th><th>Epoch 2</th><th>Epoch 3</th><th>Epoch 4</th></tr>
  <tr align="center"><th rowspan="2">학습데이터</th><td>평균 학습 오차</td><td>0.58</td><td>0.37</td><td>0.24</td><td>0.15</td></tr>
  <tr align="center"><td>검증 정확도</td><td>0.74</td><td>0.86</td><td>0.87</td><td>0.89</td></tr>
</table>

학습 데이터의 평균 학습 오차가 학습이 진행될 수록 감소되는 것을 볼 수 있다. Epoch 1에서 0.58이었지만 Epoch 4에서는 0.15로 감소하였으며 이는 모델이 학습 데이터에 대해 점점 더 효과적으로 학습되고 있다는 것을 알 수 있다. 
또한 검증 정확도도 에폭이 진행됨에 따라 검증 정확도가 0.74에서 0.89까지 상승하였다.

## 3.4 모델 적용

학습 모델을 전체 데이터(63,683건)에 적용한 결과

```
test steps :  1 Accuracy :  0.875
test steps :  2 Accuracy :  0.625
test steps :  3 Accuracy :  0.875
...
test steps :  7959 Accuracy :  1.0
test steps :  7960 Accuracy :  0.875
test steps :  7961 Accuracy :  0.6666666666666666
Accuracy: 0.74
test took: 2:30:16
```

학습 모델을 전체 데이터에 적용한 결과 값은 예측 정확도가 0.74가 나왔다.

# 4. 결론 및 배운점 

랜덤으로 추출한 학습 데이터셋은 0.4 에서 0.7로 매우 낮은 정확도를 나타냈다. 데이터를 확인해보니 긍정인 리뷰가 부정으로 분류되어있거나 부정이 아닌 리뷰가 긍정으로 분류되어 있는 데이터가 매우 많았다.
스팀의 평가 시스템 특성상 점수 제도가 아닌 긍정 혹은 부정이기 때문에 애매하게 적힌 리뷰들이 많았다. 또한 게임 이름과 게임 용어들, 비속어 및 은어가 사용된 리뷰가 매우 많았으며 리뷰와 관련 없이 질문하는 내용의 데이터들도 있었다. 그래서 직접 게임 리뷰를 하나씩 읽으며 긍정과 부정이 올바르게 분류되어있고, 리뷰를 읽었을 때 부정인지 긍정인지 판단이 될 만한 데이터만 1000개를 추출하여 만들었다. 임의로 추출해낸 1000건의 학습 데이터셋은 0.89의 높은 정확도를 나타냈다. 0.9 이상이 나오지 않는 것은 게임 이름과 게임 용어가 쓰여진 리뷰 때문일 가능성이라고 생각된다. 이 학습 모델을 전체 데이터에 적용한 결과 값은 0.74로, 좋은 성능은 아니지만 예상보다는 높게 나왔다. 전체 데이터셋이 랜덤으로 추출했던 학습 데이터셋의 정확도보다 높다는 것은 꽤 의미가 있다고 생각된다.긍정,부정 라벨이 올바르게 분류 되어있고 리뷰 내용에 오류가 없는 데이터들은 어느정도 예측한 것으로 보인다. 마지막으로 이 프로젝트를 하며 배운 점은 데이터의 중요성을 느꼈으며 데이터의 전처리는 모델의 성능에 큰 영향을 미친다는 것을 몸소 배웠다.
